{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime\n",
    "import sys\n",
    "from os import path, environ\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "sys.path.insert(0, path.abspath('../../../pyTorchBridge/'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from utils import contiguous_sequences\n",
    "from plotting import model_surface, plot_surface\n",
    "from condenser import Condenser\n",
    "\n",
    "chiller_file = path.join(environ['DATADIR'],\n",
    "                         'EngineeringScienceBuilding',\n",
    "                         '2422_ESB_HVAC.csv')\n",
    "plot_path = path.join('..', 'docs', 'img')\n",
    "bin_path = './bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data selection 'all' or 'chiller_on' or 'fan_on'\n",
    "MODE = 'chiller_on'\n",
    "# Read pre-processed data:\n",
    "# Pytorch uses float32 as default type for weights etc,\n",
    "# so input data points are also read in the same type.\n",
    "df = pd.read_csv(chiller_file, index_col='time',\n",
    "                 parse_dates=['time'], dtype=np.float32)\n",
    "df.drop(['PowFanA', 'PowFanB', 'FlowCond', 'PowChiP', 'PerFreqConP', 'PowConP'], axis='columns', inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "if MODE == 'chiller_on':\n",
    "    df = df[df['PowChi'] != 0.]\n",
    "if MODE == 'fan_on':\n",
    "    df = df[(df['PerFreqFanA'] != 0.) | df['PerFreqFanB'] != 0.]\n",
    "print(len(df), 'Records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment model\n",
    "\n",
    "State variables (8):\n",
    "\n",
    "`'TempCondIn', 'TempCondOut', 'TempAmbient', 'TempWetBulb', 'TempEvapIn', 'TempEvapOut', 'PressDiffEvap', 'PressDiffCond'`\n",
    "\n",
    "Action variables (1):\n",
    "\n",
    "`'TempCondInSetpoint'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condenser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envvars = ['TempCondIn', 'TempCondOut', 'TempAmbient', 'TempWetBulb', 'TempEvapIn', 'TempEvapOut', 'PressDiffEvap', 'PressDiffCond']\n",
    "actionvars = ['TempCondInSetpoint']\n",
    "inputs =  actionvars + envvars \n",
    "outputs = ['PowChi', 'TempCondOut', 'TempCondIn']\n",
    "lag = (1, 1, 1)    # 0, 1, 2, 3, 4, ...\n",
    "\n",
    "df_in = pd.DataFrame(columns=inputs, index=df.index)\n",
    "df_in['TempCondInSetpoint'] = np.clip(df['TempWetBulb'] - 4, a_min=65, a_max=None)  # approach controller\n",
    "df_in[inputs[1:]] = df[inputs[1:]]\n",
    "\n",
    "df_out = pd.DataFrame(columns=outputs, index=df.index)\n",
    "df_out[outputs] = df[outputs]\n",
    "\n",
    "idx_list = contiguous_sequences(df.index, pd.Timedelta(5, unit='min'), filter_min=10)\n",
    "\n",
    "# Create dataframes of contiguous sequences with a delay\n",
    "# of 1 time unit to indicate causality input -> outputs\n",
    "dfs_in, dfs_out = [], []\n",
    "for idx in idx_list:\n",
    "    dfs_in.append(df_in.loc[idx[:-max(lag) if max(lag) > 0 else None]])\n",
    "    cols = []\n",
    "    for l, c in zip(lag, outputs):\n",
    "        window = slice(l, None if l==max(lag) else -(max(lag)-l))\n",
    "        series = df_out[c].loc[idx[window]]\n",
    "        cols.append(series.values)\n",
    "        if l == min(lag): index = series.index\n",
    "    dfs_out.append(pd.DataFrame(np.asarray(cols).T, index=index, columns=outputs))\n",
    "\n",
    "df_in = pd.concat(dfs_in, sort=False)\n",
    "df_out = pd.concat(dfs_out, sort=False)\n",
    "\n",
    "print('{:6d} time series'.format(len(dfs_in)))\n",
    "print('{:6d} total rows'.format(len(df_in)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "std_in_cond, std_out_cond = StandardScaler(), StandardScaler()\n",
    "net = MLPRegressor(hidden_layer_sizes=(64, 32, 16),\n",
    "                   activation='tanh',\n",
    "                   solver='adam',\n",
    "                   verbose=True,\n",
    "                   early_stopping=True,\n",
    "                   learning_rate_init=1e-3)\n",
    "est_cond = Pipeline([('std', std_in_cond), ('net', net)])\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', category=FutureWarning)\n",
    "    est_cond.fit(df_in, std_out_cond.fit_transform(df_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "save = {\n",
    "    'loss': est_cond['net'].loss_,\n",
    "    'estimator': est_cond,\n",
    "    'output_norm': std_out_cond,\n",
    "    'inputs': inputs,\n",
    "    'outputs': outputs\n",
    "}\n",
    "with open(path.join(bin_path, 'env_condenser_condenser_nn'), 'wb') as f:\n",
    "    pickle.dump(save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "with open(path.join(bin_path, 'env_condenser_condenser_nn'), 'rb') as f:\n",
    "    save = pickle.load(f, fix_imports=False)\n",
    "    est_cond = save['estimator']\n",
    "    std_out = save['output_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model predictions\n",
    "test_in, test_out = dfs_in[2], dfs_out[2]\n",
    "pred = pd.DataFrame(std_out.inverse_transform(est_cond.predict(test_in)),\n",
    "                    index=test_out.index, columns=test_out.columns)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "test_in.loc[:, ('TempCondIn')].plot(grid=True, style=':', label='TempCondIn')\n",
    "test_out.loc[:, ('TempCondIn')].plot(grid=True, style=':', label='TempCondIn-Next')\n",
    "pred.loc[:, ('TempCondIn')].plot(grid=True, style=':', label='TempCondIn-Next-Pred')\n",
    "test_in.loc[:, ('TempCondOut')].plot(grid=True, style=':', label='TempCondOut')\n",
    "test_out.loc[:, ('TempCondOut')].plot(grid=True, style=':', label='TempCondOut-Next')\n",
    "pred.loc[:, ('TempCondOut')].plot(grid=True, style=':', label='TempCondOut-Next-Pred')\n",
    "plt.legend()\n",
    "plt.subplot(2, 1, 2)\n",
    "ax4 = test_out.loc[:, ('PowChi')].plot(grid=True, label='PowChi')\n",
    "ax5 = pred.loc[:, ('PowChi')].plot(grid=True, label='PowChi-Pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = df_in.loc['2019-07-01T1200-6'].values.reshape(1, -1)\n",
    "x, y, z = model_surface(lambda x: std_out_cond.inverse_transform(est_cond.predict(x))[:,2],\n",
    "                        X=point, vary_idx=(0, 3),vary_range=((65, 85), (75, 95)), vary_num=(20, 20))\n",
    "ax = plot_surface(x,y,z, cmap=plt.cm.coolwarm)\n",
    "ax.set_xlabel('TempCondInSetpoint')\n",
    "ax.set_ylabel('TempAmbient')\n",
    "ax.set_zlabel('TempCondIn-Next Cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_in.loc['2019-07-01T1200-6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Cooling Tower\n",
    "\n",
    "Note: not being used in the environment. The condenser model is now predicting the next timestep's `TempCondIn` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "envvars = ['TempCondOut', 'TempAmbient', 'TempWetBulb', 'TempEvapIn', 'TempEvapOut', 'PressDiffEvap', 'PressDiffCond']\n",
    "actionvars = ['TempCondInSetpoint']\n",
    "inputs =  actionvars + envvars\n",
    "outputs = ['TempCondIn']\n",
    "lag = 0    # 0, 1, 2, 3, 4, ...\n",
    "\n",
    "df_in = pd.DataFrame(columns=inputs, index=df.index)\n",
    "df_in['TempCondInSetpoint'] = df['TempWetBulb'] + 4  # approach controller\n",
    "df_in[inputs[1:]] = df[inputs[1:]]\n",
    "\n",
    "df_out = pd.DataFrame(columns=outputs, index=df.index)\n",
    "df_out[outputs] = df[outputs]\n",
    "\n",
    "idx_list = contiguous_sequences(df.index, pd.Timedelta(5, unit='min'), filter_min=10)\n",
    "\n",
    "# Create dataframes of contiguous sequences with a delay\n",
    "# of 1 time unit to indicate causality input -> outputs\n",
    "dfs_in, dfs_out = [], []\n",
    "for idx in idx_list:\n",
    "    dfs_in.append(df_in.loc[idx[:-lag if lag > 0 else None]])\n",
    "    dfs_out.append(df_out.loc[idx[lag:]])\n",
    "\n",
    "df_in = pd.concat(dfs_in, sort=False)\n",
    "df_out = pd.concat(dfs_out, sort=False)\n",
    "\n",
    "print('{:6d} time series'.format(len(dfs_in)))\n",
    "print('{:6d} total rows'.format(len(df_in)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "std_in_tower, std_out_tower = StandardScaler(), StandardScaler()\n",
    "net = MLPRegressor(hidden_layer_sizes=(64, 32, 16),\n",
    "                   activation='tanh',\n",
    "                   solver='adam',\n",
    "                   verbose=True,\n",
    "                   early_stopping=True,\n",
    "                   learning_rate_init=1e-3)\n",
    "est_tower = Pipeline([('std', std_in_tower), ('net', net)])\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', category=FutureWarning)\n",
    "    est_tower.fit(df_in, std_out_tower.fit_transform(df_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "save = {\n",
    "    'loss': est_tower['net'].loss_,\n",
    "    'estimator': est_tower,\n",
    "    'output_norm': std_out_tower,\n",
    "    'inputs': inputs,\n",
    "    'outputs': outputs\n",
    "}\n",
    "with open(path.join(bin_path, 'env_condenser_tower_nn'), 'wb') as f:\n",
    "    pickle.dump(save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "with open(path.join(bin_path, 'env_condenser_tower_nn'), 'rb') as f:\n",
    "    save = pickle.load(f, fix_imports=False)\n",
    "    est_tower = save['estimator']\n",
    "    std_out_tower = save['output_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Visualize model predictions\n",
    "test_in, test_out = dfs_in[2], dfs_out[2]\n",
    "pred = pd.DataFrame(std_out_tower.inverse_transform(est_tower.predict(test_in)),\n",
    "                    index=test_out.index, columns=test_out.columns)\n",
    "test_in.loc[:, ('TempCondInSetpoint', 'TempCondOut')].plot(grid=True)\n",
    "test_out.loc[:, ('TempCondIn')].plot(grid=True, style=':')\n",
    "pred.loc[:, ('TempCondIn')].plot(grid=True, style=':')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make wrapper for cooling tower such that outputs are normalized\n",
    "# i.e. in physical units instead of being 0 mean and 1 variance.\n",
    "from cooling_tower import CoolingTower\n",
    "\n",
    "externalvars = ('TempAmbient', 'TempWetBulb', 'TempEvapIn', 'TempEvapOut', 'PressDiffEvap', 'PressDiffCond')\n",
    "externalvals = [df.loc[:, externalvars] for df in dfs_in]\n",
    "\n",
    "class InvTransformer:\n",
    "    \n",
    "    def __init__(self, estimator, transformer):\n",
    "        self.estimator = estimator\n",
    "        self.transformer = transformer\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.transformer.inverse_transform(self.estimator.predict(x))\n",
    "        \n",
    "\n",
    "esb = Condenser(InvTransformer(est_cond, std_out_cond), externalvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize environment episode\n",
    "done = False\n",
    "states = []\n",
    "power = []\n",
    "esb.reset()\n",
    "while not done:\n",
    "    state, _, done, info = esb.step(esb.action_space.sample())\n",
    "    states.append(state)\n",
    "    power.append(info.get('powchi'))\n",
    "esb.reset()\n",
    "    \n",
    "states = np.asarray(states)\n",
    "power = np.asarray(power)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(power, label='Total Power')\n",
    "plt.legend()\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(states[:, 0], label='TempCondIn')\n",
    "plt.plot(states[:, 1], label='TempCondOut')\n",
    "plt.plot(states[:, 2], label='TempAmbient')\n",
    "plt.plot(states[:, 3], label='TempWetBulb')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.0043457365 |\n",
      "| clipfrac           | 0.04736328   |\n",
      "| explained_variance | 0.807        |\n",
      "| fps                | 490          |\n",
      "| n_updates          | 1            |\n",
      "| policy_entropy     | 1.4178611    |\n",
      "| policy_loss        | -0.004554482 |\n",
      "| serial_timesteps   | 128          |\n",
      "| time_elapsed       | 0            |\n",
      "| total_timesteps    | 512          |\n",
      "| value_loss         | 0.003511376  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0068328762   |\n",
      "| clipfrac           | 0.100097656    |\n",
      "| explained_variance | 0.691          |\n",
      "| fps                | 1517           |\n",
      "| n_updates          | 10             |\n",
      "| policy_entropy     | 1.3978771      |\n",
      "| policy_loss        | -0.0037712269  |\n",
      "| serial_timesteps   | 1280           |\n",
      "| time_elapsed       | 3.76           |\n",
      "| total_timesteps    | 5120           |\n",
      "| value_loss         | 0.000100123114 |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00047332034 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.832         |\n",
      "| fps                | 1495          |\n",
      "| n_updates          | 20            |\n",
      "| policy_entropy     | 1.4107119     |\n",
      "| policy_loss        | -0.0008063864 |\n",
      "| serial_timesteps   | 2560          |\n",
      "| time_elapsed       | 7.22          |\n",
      "| total_timesteps    | 10240         |\n",
      "| value_loss         | 9.3943345e-06 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0032120398   |\n",
      "| clipfrac           | 0.041015625    |\n",
      "| explained_variance | -4.33          |\n",
      "| fps                | 1513           |\n",
      "| n_updates          | 30             |\n",
      "| policy_entropy     | 1.4007572      |\n",
      "| policy_loss        | -0.00067680766 |\n",
      "| serial_timesteps   | 3840           |\n",
      "| time_elapsed       | 10.6           |\n",
      "| total_timesteps    | 15360          |\n",
      "| value_loss         | 6.4343025e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.005868512   |\n",
      "| clipfrac           | 0.08886719    |\n",
      "| explained_variance | 0.3           |\n",
      "| fps                | 1513          |\n",
      "| n_updates          | 40            |\n",
      "| policy_entropy     | 1.3987796     |\n",
      "| policy_loss        | -0.0045702755 |\n",
      "| serial_timesteps   | 5120          |\n",
      "| time_elapsed       | 14            |\n",
      "| total_timesteps    | 20480         |\n",
      "| value_loss         | 7.2725215e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0020880182  |\n",
      "| clipfrac           | 0.022949219   |\n",
      "| explained_variance | 0.426         |\n",
      "| fps                | 1517          |\n",
      "| n_updates          | 50            |\n",
      "| policy_entropy     | 1.3999249     |\n",
      "| policy_loss        | -0.0010632982 |\n",
      "| serial_timesteps   | 6400          |\n",
      "| time_elapsed       | 17.4          |\n",
      "| total_timesteps    | 25600         |\n",
      "| value_loss         | 3.131517e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0024089722  |\n",
      "| clipfrac           | 0.028320312   |\n",
      "| explained_variance | 0.362         |\n",
      "| fps                | 1531          |\n",
      "| n_updates          | 60            |\n",
      "| policy_entropy     | 1.3741724     |\n",
      "| policy_loss        | -0.0027649545 |\n",
      "| serial_timesteps   | 7680          |\n",
      "| time_elapsed       | 20.8          |\n",
      "| total_timesteps    | 30720         |\n",
      "| value_loss         | 7.0386354e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.006138832   |\n",
      "| clipfrac           | 0.08935547    |\n",
      "| explained_variance | 0.81          |\n",
      "| fps                | 1522          |\n",
      "| n_updates          | 70            |\n",
      "| policy_entropy     | 1.3747615     |\n",
      "| policy_loss        | -0.004558214  |\n",
      "| serial_timesteps   | 8960          |\n",
      "| time_elapsed       | 24.2          |\n",
      "| total_timesteps    | 35840         |\n",
      "| value_loss         | 1.7150476e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00460754    |\n",
      "| clipfrac           | 0.061035156   |\n",
      "| explained_variance | 0.815         |\n",
      "| fps                | 1513          |\n",
      "| n_updates          | 80            |\n",
      "| policy_entropy     | 1.3724912     |\n",
      "| policy_loss        | -0.0011459764 |\n",
      "| serial_timesteps   | 10240         |\n",
      "| time_elapsed       | 27.6          |\n",
      "| total_timesteps    | 40960         |\n",
      "| value_loss         | 1.1484011e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0054067136   |\n",
      "| clipfrac           | 0.067871094    |\n",
      "| explained_variance | 0.165          |\n",
      "| fps                | 1526           |\n",
      "| n_updates          | 90             |\n",
      "| policy_entropy     | 1.3891732      |\n",
      "| policy_loss        | -0.00041625166 |\n",
      "| serial_timesteps   | 11520          |\n",
      "| time_elapsed       | 31             |\n",
      "| total_timesteps    | 46080          |\n",
      "| value_loss         | 2.0953019e-05  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x19a14de7a88>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.policies import MlpPolicy, LstmPolicy\n",
    "\n",
    "class CT(CoolingTower):\n",
    "    def reward(self, t, state: np.ndarray, action: np.ndarray, nstate: np.ndarray,\n",
    "               locals: dict) -> float:\n",
    "        powchi = (locals.get('powchi') - 5300) / 415700.\n",
    "        # powfans = locals.get('powfans') / 21230\n",
    "        tempcondin = (locals.get('tempcondin') - 281.7) / 25.15\n",
    "        tempcondout = (locals.get('tempcondout') - 290.) / 20.\n",
    "\n",
    "        # return - (0.2 * powchi) - (0.8 * powfans)\n",
    "        # return - (0.9 * tempcondin) - (0.1 * powfans)\n",
    "        # return - (0.1 * powchi) - (0.9 * tempcondin)\n",
    "        return -powchi\n",
    "    \n",
    "esb_vec = DummyVecEnv([lambda: Condenser(InvTransformer(est_cond, std_out_cond), externalvals) \\\n",
    "                       for _ in range(4)])\n",
    "agent = PPO2(MlpPolicy, esb_vec, verbose=1, learning_rate=1e-3)\n",
    "agent.learn(50000, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seqidx = np.random.randint(len(dfs_in))\n",
    "seqidx = 21 # May\n",
    "simulate_hist = True  # Whether to use raw output data, or simulate it through historical actions\n",
    "\n",
    "# indexing histories after 1st element because simulated trajectories\n",
    "# are recorded after initial state (> 0), so lengths are equal\n",
    "act_hist = dfs_in[seqidx].loc[:, ('TempCondInSetpoint')].values[1:, None]\n",
    "ext = dfs_in[seqidx].loc[:, externalvars]\n",
    "\n",
    "# Get baseline by running historic actions through environment:\n",
    "if simulate_hist:\n",
    "    esb.reset(external=ext)\n",
    "    done = False\n",
    "    pow_hist_chi, pow_hist_fan, temp_hist = [], [], []\n",
    "    t = 0\n",
    "    while not done:\n",
    "        action = act_hist[t, :1]\n",
    "        _, _, done, info = esb.step(action)\n",
    "        # pow_hist_fan.append(info.get('powfans'))\n",
    "        pow_hist_chi.append(info.get('powchi'))\n",
    "        temp_hist.append(info.get('tempcondin'))\n",
    "        t += 1\n",
    "else:\n",
    "    pow_hist_chi = dfs_out[seqidx]['PowChi'].values\n",
    "    pow_hist_fans = dfs_out[seqidx]['PowFans'].values\n",
    "    temp_hist = dfs_out[seqidx]['TempCondIn'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfan, pchi, act, rewards, temp = [], [], [], [], []\n",
    "\n",
    "# run multiple trials over same period for stochastic policy\n",
    "for trial in range(10):\n",
    "    state = esb.reset(external=ext)\n",
    "    done = False\n",
    "    pfan.append([])\n",
    "    pchi.append([])\n",
    "    act.append([])\n",
    "    rewards.append([])\n",
    "    temp.append([])\n",
    "    while not done:\n",
    "        action = agent.predict(state)[0]\n",
    "        state, reward, done, info = esb.step(action)\n",
    "        act[-1].append(action)\n",
    "        # pfan[-1].append(info.get('powfans'))\n",
    "        pchi[-1].append(info.get('powchi'))\n",
    "        rewards[-1].append(reward)\n",
    "        temp[-1].append(info.get('tempcondin'))\n",
    "\n",
    "# get std_dev and mean of metrics\n",
    "# std_pfan = np.std(pfan, axis=0, keepdims=False)\n",
    "std_pchi = np.std(pchi, axis=0, keepdims=False)\n",
    "std_act = np.std(act, axis=0, keepdims=False)\n",
    "std_rewards = np.std(rewards, axis=0, keepdims=False)\n",
    "std_temp = np.std(temp, axis=0, keepdims=False)\n",
    "\n",
    "# pfan = np.mean(pfan, axis=0, keepdims=False)\n",
    "pchi = np.mean(pchi, axis=0, keepdims=False)\n",
    "act = np.mean(act, axis=0, keepdims=False)\n",
    "rewards = np.mean(rewards, axis=0, keepdims=False)\n",
    "temp = np.mean(temp, axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,12))\n",
    "# plt.subplot(4,1,1)\n",
    "# plt.title('Fan Power (Average RL {:.0f}W vs Historical {:.0f}W)'\\\n",
    "#           .format(np.mean(pfan), np.mean(pow_hist_fan)))\n",
    "# plt.plot(pfan, 'b:', label='RL.Fan')\n",
    "# plt.fill_between(np.arange(len(pfan)), pfan+std_pfan, pfan-std_pfan, color='b', alpha=0.3)\n",
    "# plt.plot(pow_hist_fan, 'r:', label='Historical.Fan')\n",
    "# plt.ylim(bottom=0)\n",
    "# plt.legend()\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.title('Chiller Power (Average RL {:.0f}W vs Historical {:.0f}W)'\\\n",
    "          .format(np.mean(pchi), np.mean(pow_hist_chi)))\n",
    "plt.plot(pchi, 'b:', label='RL.Chiller')\n",
    "plt.fill_between(np.arange(len(pchi)), pchi+std_pchi, pchi-std_pchi, color='b', alpha=0.3)\n",
    "plt.plot(pow_hist_chi, 'r:', label='Historical.Chiller')\n",
    "plt.ylim(bottom=0)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.title('Setpoint Control (Average RL {:.2f} vs Historical {:.2f})'\\\n",
    "          .format(np.mean(act[:, 0]), np.mean(act_hist[:, 0])))\n",
    "plt.plot(act[:, 0], 'b:', label='RL.Setpoint')\n",
    "plt.fill_between(np.arange(len(act[:, 0])), act[:, 0]+std_act[:, 0], act[:, 0]-std_act[:, 0], color='b', alpha=0.3)\n",
    "plt.plot(act_hist[:, 0], 'r:', label='Historical.Setpoint')\n",
    "# plt.ylim(top=1.05)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.title('Output Temperature (Average RL {:.1f}F vs Historical {:.1f}F)'\\\n",
    "          .format(np.mean(temp), np.mean(temp_hist)))\n",
    "plt.plot(temp, 'b:', label='RL.Temp')\n",
    "plt.fill_between(np.arange(len(temp)), temp+std_temp, temp-std_temp, color='b', alpha=0.3)\n",
    "plt.plot(temp_hist, 'r:', label='Historical.Temp')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(k2f(dfs_in[seqidx]['TempAmbient'].values), label='Ambient Temp')\n",
    "plt.plot(k2f(dfs_in[seqidx]['TempWetBulb'].values), label='WetBulb Temp')\n",
    "plt.legend()\n",
    "plt.ylabel('Temperature /F')\n",
    "plt.title('Environmental Conditions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
