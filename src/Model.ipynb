{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime\n",
    "from os import path, environ\n",
    "from copy import deepcopy\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models import fit_composite_model\n",
    "# source file, see docs/5-dataset.md for info on field names\n",
    "chiller_file = path.join(environ['DATADIR'], 'EngineeringScienceBuilding', 'Chillers.csv')\n",
    "plot_path = path.join('..', 'docs', 'img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pre-processed data\n",
    "df = pd.read_csv(chiller_file, index_col='Time', parse_dates=True, dtype=float)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaporative Cooling Model\n",
    "\n",
    "Modelling the relationship between the cooling done by the cooling tower and the environmental, system, and control inputs.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(t) &= T(0) e^{-\\frac{k T_a v_f R}{T_w c_m m} t}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $T(0)$ is the warm entering water temperature `TempCondOut`,\n",
    "* $T(t)$ is the exiting cool water temperature `TempCondIn`,\n",
    "* $T_a$ is ambient air temperature `TempAmbient`,\n",
    "* $v_f$ is avarage fan speed `0.5 * (PerFreqFanA + PerFreqFanB)`,\n",
    "* $R$ is solar irradiance - constant if assuming shade.\n",
    "* $T_w$ is wet-bulb temperature `TempWetBulb`,\n",
    "* $c_m$ is specific mass heat capacity of water,\n",
    "* $m$ is the mass of water being cooled - constant if assuming steady flow rate.\n",
    "\n",
    "The model predicts $T(t)$ from all other factors.\n",
    "\n",
    "## Multi-Layer Perceptron\n",
    "\n",
    "The motivation for an MLP model is the assumption that inputs manifest instantaneously as outputs with not delay. This is a simplification as water takes some time to cycle through the cooling tower.\n",
    "\n",
    "The inputs are chosen assuming steady flow rate, constant irradiance.\n",
    "\n",
    "The control variables are `PerFreqFanA` and `PerFreqFanB` which usually track each other. They are distributed bi-modally around 100% and 0% power with a minority of samples falling in between. A concern is that the model may learn to treat control inputs as constant. Two approaches are chosen:\n",
    "\n",
    "* A single model is learned over all data,\n",
    "* Samples are clustered by control=0, control >= 0.95, and 0 < control  < 0.95. A separate model is learned for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "feature_cols = ['TempCondOut', 'PerFreqFanA', 'PerFreqFanB', 'TempAmbient', 'TempWetBulb'] \n",
    "X, Y = df.loc[:, feature_cols], df['TempCondIn']\n",
    "# setting up cluster selectors\n",
    "c1 = df['PerFreqFanA'] >= 0.95\n",
    "c0 = df['PerFreqFanA'] == 0 \n",
    "cmid = ~ (c1 | c0)\n",
    "# generating clusters\n",
    "X1, Y1 = X[c1], Y[c1]\n",
    "Xmid, Ymid = X[cmid], Y[cmid]\n",
    "X0, Y0 = X[c0], Y[c0]\n",
    "# generating training/testing sets for each cluster\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.1)\n",
    "X1train, X1test, Y1train, Y1test = train_test_split(X1, Y1, test_size=0.1)\n",
    "Xmidtrain, Xmidtest, Ymidtrain, Ymidtest = train_test_split(Xmid, Ymid, test_size=0.1)\n",
    "X0train, X0test, Y0train, Y0test = train_test_split(X0, Y0, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "scaler = StandardScaler()              # scale to 0 mean and unit variance\n",
    "regressor = MLPRegressor(hidden_layer_sizes=(20,20), \n",
    "                         learning_rate_init=1e-3,\n",
    "                         verbose=True) # regression model\n",
    "est = Pipeline([('scaler', scaler), ('regressor', regressor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Score on all control:\\t{:.4f}'.format(est.score(Xtest, Ytest)))\n",
    "print('Score on >95%-control:\\t{:.4f}'.format(est.score(X0test, Y0test)))\n",
    "print('Score on mid-control:\\t{:.4f}'.format(est.score(X1test, Y1test)))\n",
    "print('Score on 0%-control:\\t{:.4f}'.format(est.score(Xmidtest, Ymidtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composite MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()              # scale to 0 mean and unit variance\n",
    "regressor = MLPRegressor(hidden_layer_sizes=(20,20), \n",
    "                         learning_rate_init=1e-3,\n",
    "                         verbose=False,\n",
    "                         max_iter=1000,\n",
    "                         solver='adam') # regression model\n",
    "est = Pipeline([('scaler', scaler), ('regressor', regressor)])\n",
    "\n",
    "est1, estmid, est0 = fit_composite_model(est, zip((X1train, Xmidtrain, X0train),\n",
    "                                                  (Y1train, Ymidtrain, Y0train)))\n",
    "print('Loss on >95%-control:\\t{:.4f}'.format(est1.named_steps['regressor'].loss_))\n",
    "print('Loss on mid-control:\\t{:.4f}'.format(estmid.named_steps['regressor'].loss_))\n",
    "print('Loss on 0%-control:\\t{:.4f}'.format(est0.named_steps['regressor'].loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on all control:\t0.8641\n",
      "Score on >95%-control:\t0.8700\n",
      "Score on mid-control:\t0.6506\n",
      "Score on 0%-control:\t0.9793\n"
     ]
    }
   ],
   "source": [
    "score1 = est1.score(X1test, Y1test)\n",
    "scoremid = estmid.score(Xmidtest, Ymidtest)\n",
    "score0 = est0.score(X0test, Y0test)\n",
    "scoreall = (len(X1test)*score1 + len(Xmidtest)*scoremid + len(X0test)*score0) / len(Xtest)\n",
    "print('Score on all control:\\t{:.4f}'.format(scoreall))\n",
    "print('Score on >95%-control:\\t{:.4f}'.format(score1))\n",
    "print('Score on mid-control:\\t{:.4f}'.format(scoremid))\n",
    "print('Score on 0%-control:\\t{:.4f}'.format(score0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
