{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from itertools import zip_longest, product\n",
    "from collections import namedtuple\n",
    "\n",
    "import notebook_setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tslearn.utils import to_time_series\n",
    "from tslearn.metrics import dtw\n",
    "from sklearn import metrics\n",
    "from sklearn import cluster\n",
    "from sklearn import manifold\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import gym\n",
    "import optuna\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n",
    "from bdx import get_trend\n",
    "from utils import get_credentials\n",
    "from commonml import rl, helpers, stats\n",
    "from systems import CoolingTowerEnv, CoolingTowerIOEnv\n",
    "from plotting import model_surface, plot_surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "* ESB Chiller 1 data (2422) `2021-03-18 1220-5` to `2021-03-26 1010-5`, `2021-05-25 0000-5` to `2021-06-08 0000-5`\n",
    "* ESB Chiller 2 data (2841) `2021-03-26 1010-5` to `2021-05-16 0610-5`\n",
    "* ESB Python setpoint data (3481)\n",
    "* Kissam data (2661) `2021-06-03 0000-5` to `2021-08-31`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cst = timezone(offset=-timedelta(hours=6))\n",
    "cdt = timezone(offset=-timedelta(hours=5))\n",
    "\n",
    "datadir = os.path.join(os.environ.get('DATADIR'), 'EngineeringScienceBuilding')\n",
    "username, password = get_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Download and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get data from BDX for chiller systems\n",
    "# ESB Cooling tower 1\n",
    "ch1 = get_trend('2422', username, password,\n",
    "               start=datetime(2021,8,1, tzinfo=cdt),\n",
    "               end=datetime(2021,11,1, tzinfo=cdt))\n",
    "# ch1 = ch1.append(get_trend('2422', username, password,\n",
    "#                  start=datetime(2021,5,25,0,0, tzinfo=cdt),\n",
    "#                  end=datetime(2021,6,8,0,0, tzinfo=cdt)))\n",
    "\n",
    "# ESB Cooling tower 2\n",
    "ch2 = get_trend('2841', username, password,\n",
    "               start=datetime(2021,3,26,10,10, tzinfo=cdt),\n",
    "               end=datetime(2021,5,16,6,10, tzinfo=cdt))\n",
    "\n",
    "# ESB setpoint\n",
    "stpt = get_trend('3481', username, password,\n",
    "               start=datetime(2021,8,1, tzinfo=cdt),\n",
    "               end=datetime(2021,11,1, tzinfo=cdt))\n",
    "# stpt = stpt.append(get_trend('3481', username, password,\n",
    "#                    start=datetime(2021,5,25,0,0, tzinfo=cdt),\n",
    "#                    end=datetime(2021,6,8,0,0, tzinfo=cdt)))\n",
    "stpt = stpt['CDWTPythonSetpt']\n",
    "\n",
    "# Merge setpoint w/ data\n",
    "ch1['Setpoint'] = stpt.loc[ch1.index]\n",
    "ch2['Setpoint'] = stpt.loc[ch2.index]\n",
    "\n",
    "ch1.to_csv(os.path.join(datadir, '2422_RLEM_esb_chiller1_model.csv'))\n",
    "# ch2.to_csv(os.path.join(datadir, '2841_RLEM_esb_chiller2_model.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Kissam\n",
    "chk = get_trend('2661', username, password,\n",
    "               start=datetime(2021,6,3,0,0, tzinfo=cdt),\n",
    "               end=datetime(2021,8,31,0,0, tzinfo=cdt))\n",
    "renames = {'EffectiveTempCondInSetpoint': 'Setpoint'}\n",
    "drops = ['TempCondInSetpoint']\n",
    "df = chk.copy()\n",
    "\n",
    "for column in chk.columns:\n",
    "    if column.startswith('CT_1.'):\n",
    "        fieldname = column[5:]\n",
    "        chk[column] = (chk[column] + chk['CT_2.' + fieldname]) / 2\n",
    "        renames[column] = fieldname\n",
    "        drops.append('CT_2.' + fieldname)\n",
    "    elif column.startswith('CH_1.'):\n",
    "        fieldname = column[5:]\n",
    "        chk[column] = (chk[column] + chk['CH_2.' + fieldname]) / 2\n",
    "        renames[column] = fieldname\n",
    "        drops.append('CH_2.' + fieldname)\n",
    "chk.rename(columns=renames, inplace=True)\n",
    "chk.drop(columns=drops, inplace=True)\n",
    "\n",
    "chk.to_csv(os.path.join(datadir, '2661_RLEM_kissam_chiller_model.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get naive reference data from BDX\n",
    "refstart, refend = datetime(2020,3,1, tzinfo=cst), datetime(2021,3,8, tzinfo=cst)\n",
    "stpt_ref = get_trend('3481', username, password,\n",
    "               start=refstart, end=refend)\n",
    "\n",
    "stpt_ref = stpt_ref['JCI Cooling_Tower_Water_Setpoint']\n",
    "\n",
    "ch1_ref = get_trend('2422', username, password,\n",
    "                   start=refstart, end=refend)\n",
    "ch1_ref = ch1_ref.loc[(ch1_ref['RunChi']==True) & (ch1_ref['PowChi'] > 0)]\n",
    "\n",
    "ch2_ref = get_trend('2841', username, password,\n",
    "                   start=refstart, end=refend)\n",
    "ch2_ref = ch2_ref.loc[(ch2_ref['RunChi']==True) & (ch2_ref['PowChi'] > 0)]\n",
    "\n",
    "ch1_ref_stpt = stpt_ref.loc[ch1_ref.index]\n",
    "ch2_ref_stpt = stpt_ref.loc[ch2_ref.index]\n",
    "ch1_ref['Setpoint'] = ch1_ref_stpt\n",
    "ch2_ref['Setpoint'] = ch2_ref_stpt\n",
    "\n",
    "ch1_ref = ch1_ref[~ch1_ref['Setpoint'].isna()]\n",
    "ch2_ref = ch2_ref[~ch2_ref['Setpoint'].isna()]\n",
    "\n",
    "ch1_ref.to_csv(os.path.join(datadir, '2422_RLEM_esb_chiller1_eval.csv'))\n",
    "ch2_ref.to_csv(os.path.join(datadir, '2841_RLEM_esb_chiller2_eval.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save data to disk\n",
    "ch1.to_csv(os.path.join(datadir, '2422_RLEM_esb_chiller1_model.csv'))\n",
    "ch2.to_csv(os.path.join(datadir, '2841_RLEM_esb_chiller2_model.csv'))\n",
    "chk.to_csv(os.path.join(datadir, '2661_RLEM_kissam_chiller_model.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save reference data to disk\n",
    "ch1_ref.to_csv(os.path.join(datadir, '2422_RLEM_esb_chiller1_eval.csv'))\n",
    "ch2_ref.to_csv(os.path.join(datadir, '2841_RLEM_esb_chiller2_eval.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from disk\n",
    "ch1 = pd.read_csv(os.path.join(datadir, '2422_RLEM_esb_chiller1_model.csv'), index_col='time', parse_dates=True)\n",
    "ch2 = pd.read_csv(os.path.join(datadir, '2841_RLEM_esb_chiller2_model.csv'), index_col='time', parse_dates=True)\n",
    "chk = pd.read_csv(os.path.join(datadir, '2661_RLEM_kissam_chiller_model.csv'), index_col='time', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ref data from disk\n",
    "ch1_ref = pd.read_csv(os.path.join(datadir, '2422_RLEM_esb_chiller1_eval.csv'), index_col='time', parse_dates=True)\n",
    "ch2_ref = pd.read_csv(os.path.join(datadir, '2841_RLEM_esb_chiller2_eval.csv'), index_col='time', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models & Environments\n",
    "\n",
    "Time-independent state space. `[x]-> y` where `[Ambient, Chiller, Setpoint] -> [Next Condenser Water Temp]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataConfig = namedtuple('DataConfig', ['colsx', 'colsy', 'ticker_vars', 'lag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for the data-model for environment\n",
    "# State + action variables\n",
    "cfg1 = cfg2 = DataConfig(\n",
    "    colsx = [\n",
    "        # Ambient\n",
    "        'TempWetBulb', 'TempAmbient',\n",
    "        # Machine temperatures\n",
    "        'TempCondIn', 'TempCondOut',\n",
    "        # Machine state\n",
    "        'Tonnage', 'PressDiffCond',\n",
    "        # Action\n",
    "        'Setpoint'\n",
    "    ],\n",
    "    # Variables for cooling tower conditions that are staged\n",
    "    ticker_vars = ['TempWetBulb', 'TempAmbient', 'Tonnage', 'PressDiffCond'],\n",
    "    lag = 1,\n",
    "    colsy = ['TempCondIn', 'TempCondOut', 'PowFanA'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env_data(\n",
    "    df, colsx, colsy, ticker_vars,\n",
    "    lag=1, train_split=0.9, group_days=False, shuffle=False, seed=0\n",
    "):\n",
    "    random = np.random.RandomState(seed=seed)\n",
    "    data = df.loc[:, list(set(colsx+colsy+ticker_vars))]\n",
    "    index = data.dropna(axis=0, how='any').index\n",
    "    data = data.loc[index]\n",
    "    assert not pd.isnull(data).any(1).any(), 'Null found'\n",
    "    ticker = [day_data for date, day_data in data[ticker_vars].groupby(data.index.date)]\n",
    "    ticker = [t for t in ticker if len(t)==288] # all samples for a day\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler.fit(data.loc[data.index[:-lag], colsx].values)\n",
    "    if not group_days:\n",
    "        x = scaler.transform(data.loc[data.index[:-lag], colsx].values)\n",
    "        y = data.loc[data.index[lag:], colsy].to_numpy().squeeze()\n",
    "        if train_split == 1.:\n",
    "            x_train, x_val, y_train, y_val = x, [], y, []\n",
    "        else:\n",
    "            x_train, x_val, y_train, y_val = train_test_split(x, y, train_size=train_split, shuffle=shuffle)\n",
    "    else:\n",
    "        x, y = [], []\n",
    "        for date, day_data in data.groupby(data.index.date):\n",
    "            x_, y_ = day_data[colsx], day_data[colsy]\n",
    "            x_ = scaler.transform(x_.values)\n",
    "            x.append(x_[:-lag])\n",
    "            y.append(y_[lag:])\n",
    "        n_train = int(train_split * len(x))\n",
    "        indices = np.arange(len(x), dtype=int)\n",
    "        if shuffle:\n",
    "            train_idx = random.choice(indices, replace=False, size=n_train)\n",
    "        else:\n",
    "            train_idx = indices[:n_train]\n",
    "        val_idx = [i for i in indices if i not in train_idx]\n",
    "        x_train, y_train = [x[i] for i in train_idx], [y[i] for i in train_idx]\n",
    "        x_val, y_val = [x[i] for i in val_idx], [y[i] for i in val_idx]\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val, ticker, scaler\n",
    "\n",
    "def train_model(x, y, verbose=False, **model_params):\n",
    "    params = dict(hidden_layer_sizes=(48,48,32), learning_rate_init=1e-4, max_iter=500, verbose=verbose)\n",
    "    params.update(model_params)\n",
    "    model = MLPRegressor(**params)\n",
    "    model.fit(x, y)\n",
    "    return model\n",
    "\n",
    "def get_env(model_fn, scaler_fn, ticker, seed=0):\n",
    "    if isinstance(model_fn, sklearn.base.BaseEstimator):\n",
    "        model_fn = model_fn.predict\n",
    "    if isinstance(scaler_fn, sklearn.base.TransformerMixin):\n",
    "        scaler_fn = scaler_fn.transform\n",
    "    return CoolingTowerEnv(model_fn, ticker, seed, scaler_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESB Cooling Tower 1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train1, x_val1, y_train1, y_val1, ticker1, scaler1 = get_env_data(ch1, cfg1.colsx, cfg1.colsy, cfg1.ticker_vars)\n",
    "model1 = train_model(x_train1, y_train1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "xx = x_val1[:200]\n",
    "xx_ = scaler1.inverse_transform(xx)\n",
    "yy = y_val1[:200]\n",
    "yp = model1.predict(xx)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(yp[:,0], label='TempCondIn-pred')\n",
    "plt.plot(yp[:,1], label='TempCondOut-pred')\n",
    "plt.plot(xx_[:,0], label='TempWetBulb', ls=':')\n",
    "plt.plot(xx_[:,2], label='TempCondOut-last', ls=':')\n",
    "plt.legend()\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(yy[:,2], label='PowFan-pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "stpts = [55., 60., 65., 70., 75.]\n",
    "for stpt in stpts:\n",
    "    env1 = get_env(model1, scaler1, ticker1, 0)\n",
    "    scaled_stpt = env1.scale_setpoint([stpt])\n",
    "    rewards = helpers.rewards(env1, lambda x: scaled_stpt)[0]\n",
    "    plt.plot(rewards, label='{:.0f}, total:{:.0f}'.format(stpt, sum(rewards)))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ESB Cooling Tower 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train2, x_val2, y_train2, y_val2, ticker2, scaler2 = get_env_data(ch2, cfg2.colsx, cfg2.colsy, cfg2.ticker_vars)\n",
    "model2 = train_model(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xx = data.loc[data.index[:2000], colsx]\n",
    "xx = scaler2.transform(xx)\n",
    "yy = model2.predict(xx)\n",
    "plt.figure(figsize=(10,5))\n",
    "# plt.plot(np.arange(len(yy)), yy[:, 0], label='TempCondIn-Pred')\n",
    "# plt.plot(np.arange(len(yy)), ch2.loc[ch2.index[1:501], 'TempCondIn'].to_numpy().squeeze(), label='TempCondIn', ls=':')\n",
    "# plt.plot(np.arange(len(yy)), ch2.loc[ch2.index[:500], 'TempCondIn'].to_numpy().squeeze(), label='TempCondIn-Last', ls=':')\n",
    "# plt.legend()\n",
    "# plt.twinx()\n",
    "plt.plot(np.arange(len(yy)), yy[:, 2], label='PowFanA-Pred')\n",
    "plt.plot(np.arange(len(yy)), ch2.loc[data.index[1:2001], 'PowFanA'].to_numpy().squeeze(), label='PowFanA', ls=':')\n",
    "plt.plot(np.arange(len(yy)), ch2.loc[data.index[0:2000], 'PowFanA'].to_numpy().squeeze(), label='PowFanA-Last', ls=':')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "stpts = [55., 60., 65., 70., 75.]\n",
    "for stpt in stpts:\n",
    "    env2 = get_env(model2, scaler2, ticker2, 0)\n",
    "    scaled_stpt = env2.scale_setpoint([stpt])\n",
    "    rewards = helpers.rewards(env2, lambda x: scaled_stpt)[0]\n",
    "    plt.plot(rewards, label='{:.0f}, total:{:.0f}'.format(stpt, sum(rewards)))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Kissam Combined Cooling Tower Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Kissam condenser differential pressure sensor is not set, so using\n",
    "# condenser motor frequency\n",
    "cfgk = DataConfig(\n",
    "    colsx = [\n",
    "        # Ambient\n",
    "        'TempWetBulb', 'TempAmbient',\n",
    "        # Machine temperatures\n",
    "        'TempCondOut',\n",
    "        # Machine state\n",
    "        'Tonnage', 'PerFreqConP',\n",
    "        # Action\n",
    "        'Setpoint'\n",
    "    ],\n",
    "    colsy = ['TempCondIn', 'TempCondOut', 'PowFan'],\n",
    "    ticker_vars = ['TempWetBulb', 'TempAmbient', 'Tonnage', 'PerFreqConP'],\n",
    "    lag = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_traink, x_valk, y_traink, y_valk, tickerk, scalerk = get_env_data(chk, cfgk.colsx, cfgk.colsy, cfgk.ticker_vars)\n",
    "modelk = train_model(x_traink, y_traink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xx = chk.loc[chk.index[:288], colsxk]\n",
    "xx = scalerk.transform(xx)\n",
    "yy = modelk.predict(xx)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.arange(len(yy)), yy[:, 0], label='TempCondIn-Pred')\n",
    "plt.plot(np.arange(len(yy)), chk.loc[chk.index[1:289], 'TempCondIn'].to_numpy().squeeze(), label='TempCondIn', ls=':')\n",
    "plt.plot(np.arange(len(yy)), chk.loc[chk.index[:288], 'TempCondIn'].to_numpy().squeeze(), label='TempCondIn-Last', ls=':')\n",
    "plt.legend()\n",
    "plt.twinx()\n",
    "plt.plot(np.arange(len(yy)), yy[:, 2], label='PowFan-Pred')\n",
    "plt.plot(np.arange(len(yy)), chk.loc[chk.index[1:289], 'PowFan'].to_numpy().squeeze(), label='PowFan', ls=':')\n",
    "plt.plot(np.arange(len(yy)), chk.loc[chk.index[0:288], 'PowFan'].to_numpy().squeeze(), label='PowFan-Last', ls=':')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "stpts = [55., 60., 65., 70., 75.]\n",
    "for stpt in stpts:\n",
    "    envk = get_env(modelk, scalerk, tickerk, 0)\n",
    "    scaled_stpt = envk.scale_setpoint([stpt])\n",
    "    rewards = helpers.rewards(envk, lambda x: scaled_stpt)[0]\n",
    "    plt.plot(rewards, label='{:.0f}, total:{:.0f}'.format(stpt, sum(rewards)))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## System Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xt, xv, yt, yv, ticker, scaler = get_env_data(chk, colsxk, colsyk, ticker_varsk, group_days=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sippy, control\n",
    "from sippy.functionsetSIM import SS_lsim_innovation_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xt_, yt_ = np.vstack(xt), np.vstack(yt)\n",
    "xv_, yv_ = np.vstack(xv), np.vstack(yv)\n",
    "\n",
    "nx , ny, L = xt_.shape[1], yt_.shape[1], len(xt_)\n",
    "t = np.arange(len(xt_))\n",
    "system  = sippy.system_identification(yt_, xt_, 'FIR', tsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_ = np.zeros_like(yv_.T)\n",
    "t__ = np.arange(2)\n",
    "x0 = np.zeros((3, 1))\n",
    "for i in range(2, len(xv_)):\n",
    "    m = control.forced_response(system.G, t__, xv_[i-2:i].T, X0=x0[:, -1], return_x=True)\n",
    "    t_, y_[:, i-2:i], x0 = m\n",
    "y_ = y_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(y_[:,1], label='TempCondIn-Pred')\n",
    "plt.plot(yv_[:,1], label='TempCondIn')\n",
    "plt.legend()\n",
    "plt.ylim(50,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(y_[:288,2], label='PowFan-Pred')\n",
    "plt.plot(yv_[:288,2], label='PowFan')\n",
    "plt.legend()\n",
    "# plt.ylim(50,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env = CoolingTowerIOEnv(system.G, tickerk, seed=0, scaler_fn=scalerk.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "done = False\n",
    "states = []\n",
    "env.reset()\n",
    "i = 0\n",
    "while not done:\n",
    "    i += 1\n",
    "    if i == 20: break\n",
    "    state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    states.append(state)\n",
    "states = np.asarray(states)\n",
    "plt.plot(states[:, 2], label='TempCondOut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tickerk[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test data/environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_split = 0.5\n",
    "test_split = 1 - train_split\n",
    "train_sizes = np.linspace(0.25, 1.0, num=4, endpoint=True)\n",
    "group_by_day = lambda dframe: [day_data for date, day_data in dframe.groupby(dframe.index.date) if len(day_data)==288]\n",
    "\n",
    "name_df_cfg = ('CT1', 'CT2', 'K'), (ch1, ch2, chk), (cfg1, cfg2, cfgk)\n",
    "reward_baseline = -288  # baseline for episidic rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def df_train_test_split(df, train_split, shuffle=False, seed=0):\n",
    "    ntrain = int(train_split * len(df))\n",
    "    indices = df.index.to_list()\n",
    "    random = np.random.RandomState(seed=seed)\n",
    "    if shuffle: random.shuffle(indices)\n",
    "    df_train = df.loc[indices[:ntrain]]\n",
    "    df_test = df.loc[indices[ntrain:]]\n",
    "    return df_train, df_test\n",
    "\n",
    "def transfer_experiment(\n",
    "    train, test, agent_params, cfg, seed=0, timesteps=288*30, no_train=False\n",
    "):\n",
    "    agent = rl.PPO(None, **agent_params)\n",
    "    # Training environment\n",
    "    rewards_train = None\n",
    "    if not no_train:\n",
    "        if isinstance(train, pd.DataFrame):\n",
    "            x, _, y, _, ticker, scaler = get_env_data(\n",
    "                train, cfg.colsx, cfg.colsy, cfg.ticker_vars, train_split=1.\n",
    "            )\n",
    "            model = train_model(x, y)\n",
    "            env = get_env(model, scaler, ticker, seed=seed)\n",
    "            env.reset()\n",
    "        elif isinstance(train, gym.Env):\n",
    "            env = train\n",
    "        agent.env = env\n",
    "        rewards_train = agent.learn(timesteps=timesteps) if not no_train else None\n",
    "    # policy = helpers.clone(agent.policy.state_dict())\n",
    "    # Testing environment\n",
    "    if isinstance(test, pd.DataFrame):\n",
    "        x, _, y, _, ticker, scaler = get_env_data(\n",
    "            test, cfg.colsx, cfg.colsy, cfg.ticker_vars, train_split=1.\n",
    "        )\n",
    "        model = train_model(x, y)\n",
    "        env = get_env(model, scaler, ticker, seed=seed)\n",
    "    elif isinstance(test, gym.Env):\n",
    "        env = test\n",
    "    agent.env = env\n",
    "    rewards_test = agent.learn(timesteps=timesteps * 1.5)\n",
    "    \n",
    "    return rewards_train, rewards_test\n",
    "\n",
    "\n",
    "def agg_transfer_experiments(dfs, agent_params):\n",
    "    R = {}  # name -> {training set fraction -> (training reward, testing rewards)}\n",
    "    for name, (df_train, env_test, cfg) in tqdm(dfs.items(), total=len(dfs), desc='Tower'):\n",
    "        res = {}\n",
    "        for fraction in tqdm(train_sizes, leave=False, desc='Fraction'):\n",
    "            df_fraction, _ = df_train_test_split(df_train, fraction)\n",
    "            r_train, r_test = transfer_experiment(df_fraction, env_test, agent_params,\n",
    "                                                  cfg, timesteps=5000)\n",
    "            res[fraction] = (r_train, r_test)\n",
    "\n",
    "        _, r_notrain = transfer_experiment(df_fraction, env_test, agent_params,\n",
    "                                           cfg, timesteps=5000, no_train=True)\n",
    "        res[0.] = (np.ones(len(r_train)) * np.nan, r_notrain)\n",
    "        R[name] = res\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RL hyperparameter search\n",
    "def objective(trial: optuna.Trial):\n",
    "    params = dict(\n",
    "        policy = rl.ActorCriticBox,\n",
    "        activation = nn.Tanh,\n",
    "        state_dim = len(state_vars),\n",
    "        action_dim = 1,\n",
    "        n_latent_var = trial.suggest_int('n_latent_var', 16, 128),\n",
    "        lr = trial.suggest_loguniform('lr', 1e-4, 1e-1),\n",
    "        gamma = 0.,\n",
    "        epochs = trial.suggest_int('epochs', 1, 10),\n",
    "        update_interval = trial.suggest_int('update_interval', 16, 288, log=True)\n",
    "    )\n",
    "    \n",
    "    env = get_env(modelk, scalerk, tickerk, 0)\n",
    "    agent = rl.PPO(env = env, seed=0, **params)\n",
    "    rewards = agent.learn(timesteps=trial.suggest_int('timesteps', 288*10, 288*30),\n",
    "                          reward_aggregation='episodic.normalized')\n",
    "    feedback = np.mean(rewards[-5:])\n",
    "    return feedback\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "agent_params = dict(\n",
    "    policy = rl.ActorCriticBox,\n",
    "    activation = nn.Tanh,\n",
    "    state_dim = 6,\n",
    "    action_dim = 1,\n",
    "    n_latent_var = 48,\n",
    "    lr = 1e-3,\n",
    "    gamma = 0.9,\n",
    "    epochs = 5,\n",
    "    update_interval = 100,\n",
    "    truncate=False,\n",
    "    seed=0\n",
    ")\n",
    "timesteps = 288 * 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, _, y, _, ticker, scaler = get_env_data(\n",
    "    ch1, cfg1.colsx, cfg1.colsy, cfg1.ticker_vars,\n",
    "    train_split=1., shuffle=False\n",
    ")\n",
    "model = train_model(x, y, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = get_env(model, scaler, ticker, seed=0)\n",
    "env.reset()\n",
    "agent = rl.PPO(env, **agent_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = agent.learn(timesteps * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from controllers.esb import Controller as FeedbackController\n",
    "\n",
    "bounds = (58, 75)\n",
    "fc = FeedbackController((bounds,), 1, 7, 0.5, 'temperature')\n",
    "\n",
    "class RLController:\n",
    "    \n",
    "    def __init__(self, agent, state_vars, bounds):\n",
    "        self.agent, self.state_vars = agent, state_vars\n",
    "        self.bounds = np.asarray(bounds)\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        X_rl = X[self.state_vars].to_numpy(np.float32).reshape(1, -1)\n",
    "        action, logprob = self.agent.predict(X_rl)\n",
    "        action_scaled = self.bounds[0].mean() + action * 0.5 *np.diff(self.bounds[0])[0]\n",
    "        return action_scaled[0],\n",
    "rc = RLController(agent, cfg1.colsx[:-1], (bounds,))\n",
    "\n",
    "factions = []\n",
    "ractions = []\n",
    "indices = []\n",
    "feedbacks = []\n",
    "for idx, row in ch1.loc['2021-09-20':'2021-10-10'].iterrows():\n",
    "    if pd.isnull(row[cfg1.colsx]).any(): continue\n",
    "    factions.append(fc.predict(row)[0][0])\n",
    "    feedbacks.append(fc._feedbacks[-1])\n",
    "#     ractions.append(rc.predict(row)[0][0])\n",
    "    indices.append(idx)\n",
    "\n",
    "%matplotlib notebook\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(indices, factions, label='F.Setpoint', ls='-')\n",
    "plt.plot(indices, ch1.Setpoint.loc[indices], label='Actual', c='r', ls=':')\n",
    "# plt.plot(indices, ractions, label='RL', ls=':')\n",
    "plt.plot(indices, ch1.TempWetBulb.loc[indices], label='TempWetBulb')\n",
    "plt.plot(indices, ch1.TempCondIn.loc[indices], label='TempCondIn')\n",
    "plt.ylim(55, 85)\n",
    "plt.legend()\n",
    "plt.ylabel('temp')\n",
    "plt.grid('both')\n",
    "plt.twinx()\n",
    "plt.plot(indices, feedbacks, ls='-.', c='k', lw='0.5')\n",
    "plt.ylabel('feedback')\n",
    "plt.title('Re-run on measured data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from controllers.esb import Controller as BaseFBController\n",
    "\n",
    "class FBController(BaseFBController):\n",
    "\n",
    "    def feedback(self, X):\n",
    "        f = -(X[2] - X[0])\n",
    "        if np.isnan(f):\n",
    "            raise ValueError('TempCondIn is NaN. Could not calculate feedback.')\n",
    "        return f\n",
    "\n",
    "    def starting_action(self, X):\n",
    "        return np.asarray([X[0] + self.random.uniform(low=4, high=6)])\n",
    "\n",
    "    def clip_action(self, u, X):\n",
    "        return np.clip(u, a_min=max(X[0]+3., self.bounds[0][0]), a_max=self.bounds[0][1])\n",
    "\n",
    "fc = FBController((bounds,), 1, 3, 0.25, 'temperature')\n",
    "\n",
    "\n",
    "# all_tickers = pd.concat(ticker, axis=0)\n",
    "new_ticker = ch1.loc['2021-09-20':'2021-10-10', cfg1.ticker_vars]\n",
    "new_ticker.dropna(axis=0, inplace=True)\n",
    "# del all_tickers\n",
    "env = get_env(model, scaler, [new_ticker], seed=0)\n",
    "\n",
    "rewards = []\n",
    "factions = []\n",
    "indices = []\n",
    "states = []\n",
    "feedbacks = []\n",
    "for ticker_idx in trange(1, leave=False):\n",
    "    state = env.reset(ticker_idx)\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = fc.predict(state)[0]\n",
    "        action_scaled = 2 * (action - np.mean(bounds)) / (bounds[1] - bounds[0])\n",
    "        state, reward, done, _ = env.step(action_scaled)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        factions.append(action[0])\n",
    "        feedbacks.append(fc._feedbacks[-1])\n",
    "    indices.extend(env.ticker.index[:-1])\n",
    "\n",
    "states = np.asarray(states)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.grid('both')\n",
    "plt.plot(indices, factions, label='F.Setpoint')\n",
    "plt.plot(indices, ch1.loc[indices].Setpoint, label='Actual', c='r', ls=':')\n",
    "plt.plot(indices, ch1.loc[indices].TempWetBulb, label='TempWetBulb')\n",
    "# plt.plot(indices, ch1.loc[indices].TempCondIn, label='Old-TempCondIn', c='g', ls=':')\n",
    "plt.plot(indices, states[:, 2], label='TempCondIn', lw=4)\n",
    "plt.legend()\n",
    "plt.ylabel('temp')\n",
    "plt.twinx()\n",
    "plt.plot(indices, feedbacks, ls='-.', c='k', lw='0.5')\n",
    "plt.ylabel('feedback')\n",
    "plt.title('Re-run on simulated data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterdf = pd.DataFrame({\n",
    "    'Chiller load /%': df['Tonnage'] * 100/800,\n",
    "    'kw/Ton': df['PowChi'] / df['Tonnage'],\n",
    "    'Returning Water Temp /F': df['TempCondIn']\n",
    "})\n",
    "scatterdf = pd.concat((scatterdf, df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "frames = [day_data for date, day_data in scatterdf.groupby(df.index.date)]\n",
    "frames = pd.concat(frames)\n",
    "window = 288\n",
    "stride = 72\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(16,8))\n",
    "fig.colorbar(matplotlib.cm.ScalarMappable(norm=matplotlib.colors.Normalize(50,90),\n",
    "                                          cmap=matplotlib.cm.coolwarm),\n",
    "             ax=ax0)\n",
    "ax0.set_xlim(0, 100)\n",
    "ax0.set_ylim(0, 1)\n",
    "\n",
    "def func(fnum):\n",
    "    frame = frames[stride*fnum:stride*fnum+window]\n",
    "    ax0.clear()\n",
    "    ax0.grid('both')\n",
    "    ax0.set_xlim(0, 100)\n",
    "    ax0.set_ylim(0, 1)\n",
    "    ax0.set_xlabel('Chiller load /%')\n",
    "    ax0.set_ylabel('kW / ton')\n",
    "    ax0.scatter(frame['Chiller load /%'].values, frame['kw/Ton'].values, c=frame['Returning Water Temp /F'].values,\n",
    "             cmap='coolwarm', vmin=50, vmax=90)\n",
    "    fig.suptitle('%s to %s' % (frame.index[0], frame.index[-1]))\n",
    "    \n",
    "    ax1.clear()\n",
    "    ax1.grid('both')\n",
    "    ax1.set_xlim(frame.index[0], frame.index[-1])\n",
    "    ax1.set_ylim(50, 90)\n",
    "    ax1.plot(frame.index, frame.TempWetBulb, label='WetBulb')\n",
    "    ax1.plot(frame.index, frame.TempAmbient, label='Ambient')\n",
    "    ax1.plot(frame.index, frame.Setpoint, label='Setpoint')\n",
    "    ax1.plot(frame.index, frame.TempCondIn, label='TempCondIn')\n",
    "    plt.legend()\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Temperature')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylim(0, 105)\n",
    "    ax2.plot(frame.index, frame.PerFreqFanA, label='Fan Speed', c='r', ls=':')\n",
    "    plt.legend()\n",
    "\n",
    "# func(114)\n",
    "anim = FuncAnimation(fig, func, frames=(len(frames) - window) // stride, repeat=True, interval=100)\n",
    "plt.show()\n",
    "# anim.save('movie.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Transfer Across Towers\n",
    "\n",
    "Size of training set w.r.t to transfer on a different environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test environments\n",
    "dfs = {}  # name -> (training dataframe, test gym environment, dataconfig)\n",
    "for name, df, cfg in zip(name_df_cfg):\n",
    "    df_train, df_test = df_train_test_split(df, train_split)\n",
    "    if name=='K':\n",
    "    x, _, y, _, ticker, scaler = get_env_data(df_test, cfg.colsx, cfg.colsy, cfg.ticker_vars, cfg.lag, train_split=1)\n",
    "    model = train_model(x, y, verbose=False)\n",
    "    env_test = get_env(model, scaler, ticker, seed=0)\n",
    "    dfs[name] = (df_train, env_test, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "R = {}  # name -> {training set fraction -> (training reward, testing rewards)}\n",
    "for name, (df_train, env_test, cfg) in tqdm(dfs.items(), total=len(dfs), desc='Tower'):\n",
    "    res = {}\n",
    "    for fraction in tqdm(train_sizes, leave=False, desc='Fraction'):\n",
    "        df_fraction, _ = df_train_test_split(df_train, fraction)\n",
    "        r_train, r_test = transfer_experiment(df_fraction, env_test, agent_params,\n",
    "                                              cfg, timesteps=5000)\n",
    "        res[fraction] = (r_train, r_test)\n",
    "\n",
    "    _, r_notrain = transfer_experiment(df_fraction, env_test, agent_params,\n",
    "                                       cfg, timesteps=5000, no_train=True)\n",
    "    res[0.] = (np.ones(len(r_train)) * np.nan, r_notrain)\n",
    "    R[name] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,12))\n",
    "for i, (name, res) in enumerate(R.items()):\n",
    "    plt.subplot(3,1,i+1)\n",
    "    results = sorted(res.items(), key=lambda x: x[0])\n",
    "    for fraction, arrs in results:\n",
    "        tr, te = res[fraction]\n",
    "        tr = stats.rolling_mean(tr, 4) - reward_baseline\n",
    "        te = stats.rolling_mean(te, 4) - reward_baseline\n",
    "        l, *_ = plt.plot(tr, ls=':')\n",
    "        plt.plot(np.arange(len(tr)-1, len(tr)+len(te)-1), te, c=l.get_color(), label='%.2f' % fraction)\n",
    "    plt.title(name)\n",
    "    plt.ylim(0, 350)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Transfer Inside Tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "similarity_idx = ['TempWetBulb', 'TempAmbient', 'Tonnage'] # variables for judging env similarity in ticker\n",
    "dfs_c = {}  # name -> (training dataframe, test gym environment, dataconfig)\n",
    "for (name, df, cfg) in zip(*name_df_cfg):\n",
    "    _, _, _, _, ticker, _ = get_env_data(df, cfg.colsx, cfg.colsy, cfg.ticker_vars, cfg.lag, train_split=1)\n",
    "    similarity_matrix = stats.timeseries.similarity_matrix(ticker, similarity_idx)\n",
    "    clusterer = cluster.SpectralClustering(n_clusters=2, affinity='precomputed')\n",
    "    cluster_labels = clusterer.fit_predict(similarity_matrix)\n",
    "    projecter = manifold.SpectralEmbedding(affinity='precomputed')\n",
    "    coords = projecter.fit_transform(similarity_matrix)\n",
    "    # get training df and env\n",
    "    tickera = [t for label, t in zip(cluster_labels, ticker) if label==0]\n",
    "    cha = df.loc[pd.concat(tickera).index]\n",
    "    # get test df and env\n",
    "    tickerb = [t for label, t in zip(cluster_labels, ticker) if label==1]\n",
    "    chb = df.loc[pd.concat(tickerb).index]\n",
    "    x_trainb, x_valb, y_trainb, y_valb, _, scalerb = get_env_data(chb, cfg.colsx, cfg.colsy, cfg.ticker_vars)\n",
    "    modelb = train_model(x_trainb, y_trainb)\n",
    "    envb = get_env(modelb, scalerb, tickerb)\n",
    "    \n",
    "    dfs_c[name] = (cha, envb, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R_c = agg_transfer_experiments(dfs_c, agent_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,12))\n",
    "for i, (name, res) in enumerate(R_c.items()):\n",
    "    plt.subplot(3,1,i+1)\n",
    "    results = sorted(res.items(), key=lambda x: x[0])\n",
    "    for fraction, arrs in results:\n",
    "        tr, te = res[fraction]\n",
    "        tr = stats.rolling_mean(tr, 4) - reward_baseline\n",
    "        te = stats.rolling_mean(te, 4) - reward_baseline\n",
    "        l, *_ = plt.plot(tr, ls=':')\n",
    "        plt.plot(np.arange(len(tr)-1, len(tr)+len(te)-1), te, c=l.get_color(), label='%.2f' % fraction)\n",
    "    plt.title(name)\n",
    "    plt.ylim(0, 350)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "drop(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cumulative_rewards(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def drop(R, window=4):\n",
    "    for name, res in R.items():\n",
    "        print(name)\n",
    "        for fraction, (tr, te) in res.items():\n",
    "            before = stats.rolling_mean(tr)[-1] - reward_baseline\n",
    "            after = stats.rolling_mean(te)[-1] - reward_baseline\n",
    "            diff = after - before\n",
    "            per = diff * 100 / before\n",
    "            print('\\t%.2f\\t%5.2f\\t%5.2f' % (fraction, diff, per))\n",
    "drop(R_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cumulative_rewards(R):\n",
    "    for name, res in R.items():\n",
    "        print(name)\n",
    "        for fraction, (tr, te) in res.items():\n",
    "            # -288 is the worst possible reward for cooling tower\n",
    "            tot_te = sum(np.asarray(te) - reward_baseline)\n",
    "            bench = sum(np.asarray(res[0.][1]) - reward_baseline)\n",
    "            per = tot_te * 100 / bench\n",
    "            print('\\t%.2f\\t%5.2f\\t%5.2f' % (fraction, tot_te, per))\n",
    "\n",
    "cumulative_rewards(R_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
