{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime\n",
    "import sys\n",
    "from os import path, environ\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from utils import contiguous_sequences\n",
    "from plotting import model_surface, plot_surface\n",
    "from systems import Condenser\n",
    "from baseline_control import SimpleFeedbackController, FeedbackController\n",
    "\n",
    "chiller_file_1 = path.join(environ['DATADIR'],\n",
    "                         'EngineeringScienceBuilding',\n",
    "                         '2422_ESB_HVAC_1.csv')\n",
    "chiller_file_2 = path.join(environ['DATADIR'],\n",
    "                         'EngineeringScienceBuilding',\n",
    "                         '2841_ESB_HVAC_2.csv')\n",
    "\n",
    "plot_path = path.join('..', 'docs', 'img')\n",
    "bin_path = './bin/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controller script demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "from controller import make_arguments, get_settings, get_controller, update_controller, get_current_state, put_control_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = make_arguments()\n",
    "args = parser.parse_args(['-s', './local.ini'])\n",
    "settings = get_settings(args)\n",
    "settings['target'] = 'temperature'\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl = get_controller(**settings)\n",
    "update_controller(ctrl, **settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now(pytz.utc)\n",
    "start = end - timedelta(minutes=10)\n",
    "s = get_current_state(start, end, **settings)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ctrl = get_controller(**settings)\n",
    "actions = []\n",
    "feedbacks = []\n",
    "temps = []\n",
    "s['TempCondIn'] = 62.\n",
    "s['TempWetBulb'] = 40.\n",
    "for i in range(45):\n",
    "    action, = ctrl.predict(s)\n",
    "    feedbacks.append(ctrl.feedback(s))\n",
    "    actions.append(action)\n",
    "    put_control_action(action, **settings)\n",
    "    temps.append(s['TempCondIn'])\n",
    "    if i < 10:\n",
    "        s['TempCondIn'] -= 1.\n",
    "    elif i < 20:\n",
    "        s['TempCondIn'] += 1.\n",
    "    elif i < 30:\n",
    "        if actions[-1] > actions[-2]:\n",
    "            s['TempCondIn'] -= 1.\n",
    "        else:\n",
    "            s['TempCondIn'] += 1.\n",
    "    elif i < 40:\n",
    "        if actions[-1] > actions[-2]:\n",
    "            s['TempCondIn'] += 1.\n",
    "        else:\n",
    "            s['TempCondIn'] -= 1.\n",
    "    else:\n",
    "        s['TempCondIn'] -= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "# plt.imshow(np.zeros((1, 20)), aspect='auto', alpha=0.3)\n",
    "plt.plot(temps, label='Temp /F')\n",
    "plt.plot(actions, label='Setpoint /F')\n",
    "plt.grid(which='both')\n",
    "for line in (10,20,30):\n",
    "    plt.axvline(x=line, color='black', ls=':')\n",
    "plt.axhline(y=s['TempWetBulb'], label='WetBulb /F', color='red', ls='--')\n",
    "plt.axhline(y=55, label='Action lower bound', color='blue', ls='--')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.text(2, 47, 'Increasing\\n(Unresponsive)')\n",
    "plt.text(12, 47, 'Decreasing\\n(Unresponsive)')\n",
    "plt.text(22, 47, 'Same direction')\n",
    "plt.text(32, 47, 'Opposite direction')\n",
    "plt.title('Controller response to different feedback behaviors')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature /F')\n",
    "\n",
    "plt.twinx()\n",
    "plt.plot(feedbacks, 'g:', lw=3, label='feedback')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Feecback /F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Environment model\n",
    "\n",
    "State variables (12):\n",
    "\n",
    "`'TempCondIn', 'TempCondOut', 'TempEvapOut', 'PowChi', 'PowFanA', 'PowFanB', 'PowConP', 'TempEvapIn', 'TempAmbient', 'TempWetBulb', 'PressDiffEvap', 'PressDiffCond'`\n",
    "\n",
    "Action variables (1):\n",
    "\n",
    "`'TempCondInSetpoint'`\n",
    "\n",
    "Output variables (3):\n",
    "\n",
    "`'TempCondIn', 'TempCondOut', 'TempEvapOut', 'PowChi', 'PowFanA', 'PowFanB', 'PowConP'`\n",
    "\n",
    "Model:\n",
    "\n",
    "`[Action, State] --> [Output]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Choosing which chiller to use\n",
    "chiller_file = chiller_file_2\n",
    "# Data selection 'all' or 'chiller_on' or 'fan_on'\n",
    "MODE = 'chiller_on'\n",
    "# Read pre-processed data:\n",
    "# Pytorch uses float32 as default type for weights etc,\n",
    "# so input data points are also read in the same type.\n",
    "df = pd.read_csv(chiller_file, index_col='time',\n",
    "                 parse_dates=['time'], dtype=np.float32)\n",
    "print('Original length: {} Records'.format(len(df)))\n",
    "# # These fields were not populated until 2020-07-01, so leaving then out of analysis\n",
    "# df.drop(['PowFanA', 'PowFanB', 'FlowCond', 'PowChiP', 'PerFreqConP', 'PowConP'], axis='columns', inplace=True)\n",
    "df.drop(['FlowCond', 'PowChiP', 'PerFreqConP'], axis='columns', inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "if MODE == 'chiller_on':\n",
    "    df = df[df['RunChi'] != 0]\n",
    "if MODE == 'fan_on':\n",
    "    df = df[(df['RunFanA'] != 0.) | df['RunFanB'] != 0.]\n",
    "print('Processed length: {} Records'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "with open(path.join(bin_path, 'v2_condenser'), 'rb') as f:\n",
    "    save = pickle.load(f, fix_imports=False)\n",
    "    est_cond = save['estimator']\n",
    "    std_out_cond = save['output_norm']\n",
    "    statevars = save['statevars']\n",
    "    actionvars = save['actionvars']\n",
    "    inputs = save['inputs']\n",
    "    outputs = save['outputs']\n",
    "    lag = save['lag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Condenser Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_in = pd.DataFrame(columns=inputs, index=df.index)\n",
    "df_in['TempCondInSetpoint'] = np.clip(df['TempWetBulb'] - 4, a_min=65, a_max=None)  # approach controller\n",
    "df_in[inputs[1:]] = df[inputs[1:]]\n",
    "\n",
    "df_out = pd.DataFrame(columns=outputs, index=df.index)\n",
    "df_out[outputs] = df[outputs]\n",
    "\n",
    "idx_list = contiguous_sequences(df.index, pd.Timedelta(5, unit='min'), filter_min=10)\n",
    "\n",
    "# Create dataframes of contiguous sequences with a delay\n",
    "# of 1 time unit to indicate causality input -> outputs\n",
    "dfs_in, dfs_out = [], []\n",
    "for idx in idx_list:\n",
    "    dfs_in.append(df_in.loc[idx[:-max(lag) if max(lag) > 0 else None]])\n",
    "    cols = []\n",
    "    for l, c in zip(lag, outputs):\n",
    "        window = slice(l, None if l==max(lag) else -(max(lag)-l))\n",
    "        series = df_out[c].loc[idx[window]]\n",
    "        cols.append(series.values)\n",
    "        if l == min(lag): index = series.index\n",
    "    dfs_out.append(pd.DataFrame(np.asarray(cols).T, index=index, columns=outputs))\n",
    "\n",
    "df_in = pd.concat(dfs_in, sort=False)\n",
    "df_out = pd.concat(dfs_out, sort=False)\n",
    "\n",
    "print('{:6d} time series'.format(len(dfs_in)))\n",
    "print('{:6d} total rows'.format(len(df_in)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## RL Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make wrapper for cooling tower such that outputs are normalized\n",
    "# i.e. in physical units instead of being 0 mean and 1 variance.\n",
    "\n",
    "externalvars = ('TempEvapIn', 'TempAmbient', 'TempWetBulb', 'PressDiffEvap', 'PressDiffCond')\n",
    "externalvals = [df.loc[:, externalvars] for df in dfs_in]\n",
    "\n",
    "class InvTransformer:\n",
    "    \n",
    "    def __init__(self, estimator, transformer):\n",
    "        self.estimator = estimator\n",
    "        self.transformer = transformer\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.transformer.inverse_transform(self.estimator.predict(x))\n",
    "        \n",
    "\n",
    "esb = Condenser(InvTransformer(est_cond, std_out_cond), externalvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Visualize environment episode\n",
    "done = False\n",
    "states = []\n",
    "power = []\n",
    "esb.reset()\n",
    "while not done:\n",
    "    state, _, done, info = esb.step(esb.action_space.sample())\n",
    "    states.append(state)\n",
    "    power.append(info.get('powchi'))\n",
    "esb.reset()\n",
    "    \n",
    "states = np.asarray(states)\n",
    "power = np.asarray(power)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(power, label='Total Power')\n",
    "plt.legend()\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(states[:, 0], label='TempCondIn')\n",
    "plt.plot(states[:, 1], label='TempCondOut')\n",
    "plt.plot(states[:, 2], label='TempEvapOut')\n",
    "plt.plot(states[:, 4], label='TempEvapIn')\n",
    "plt.plot(states[:, 5], label='TempAmbient')\n",
    "plt.plot(states[:, 6], label='TempWetBulb')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simple Feedback Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "longest_seq_idx = max(range(len(dfs_in)), key= lambda i: len(dfs_in[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs_in[longest_seq_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# seqidx = np.random.randint(len(dfs_in))\n",
    "seqidx = longest_seq_idx\n",
    "simulate_hist = True  # Whether to use raw output data, or simulate it through historical actions\n",
    "\n",
    "# indexing histories after 1st element because simulated trajectories\n",
    "# are recorded after initial state (> 0), so lengths are equal\n",
    "act_hist = dfs_in[seqidx].loc[:, ('TempCondInSetpoint')].values[1:, None]\n",
    "ext = dfs_in[seqidx].loc[:, externalvars]\n",
    "\n",
    "# Get baseline by running historic actions through environment:\n",
    "if simulate_hist:\n",
    "    esb.reset(external=ext, state0=dfs_in[seqidx].iloc[0, 1:].values)\n",
    "    done = False\n",
    "    pow_hist_chi, pow_hist_fan, temp_hist = [], [], []\n",
    "    t = 0\n",
    "    while not done:\n",
    "        action = act_hist[t, :1]\n",
    "        _, _, done, info = esb.step(action)\n",
    "        # pow_hist_fan.append(info.get('powfans'))\n",
    "        pow_hist_chi.append(info.get('powchi'))\n",
    "        temp_hist.append(info.get('tempcondin'))\n",
    "        t += 1\n",
    "else:\n",
    "    pow_hist_chi = dfs_out[seqidx]['PowChi'].values\n",
    "    pow_hist_fans = dfs_out[seqidx]['PowFans'].values\n",
    "    temp_hist = dfs_out[seqidx]['TempCondIn'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define agent\n",
    "class Controller1(SimpleFeedbackController):\n",
    "    \n",
    "    def feedback(self, X):\n",
    "        return -sum(X[3:7])  # PowChi, PowFanA, PowFanB, PowConP\n",
    "        # return -X[0]\n",
    "    \n",
    "    def starting_action(self, X):\n",
    "        return np.asarray([X[9] + 4]) # TempWetBulb\n",
    "\n",
    "    def clip_action(self, u, X):\n",
    "        u = super().clip_action(u, X)\n",
    "        return np.clip(u, a_min=X[9], a_max=None)\n",
    "\n",
    "class Controller2(FeedbackController):\n",
    "    \n",
    "    def feedback(self, X):\n",
    "        return -X[3]  # PowChi\n",
    "    \n",
    "    def starting_action(self, X):\n",
    "        return None\n",
    "        # return X[9] + 4 # TempWetBulb\n",
    "        \n",
    "\n",
    "\n",
    "agent_fn = lambda: Controller1(bounds=((60., 80.),), stepsize=1)\n",
    "# agent_fn = lambda: Controller2(bounds=((55., 90.),), kp=1., ki=0.2, kd=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pfan, pchi, act, rewards, temp = [], [], [], [], []\n",
    "\n",
    "# run multiple trials over same period for stochastic policy\n",
    "for trial in trange(1, leave=False):\n",
    "    state = esb.reset(external=ext, state0=dfs_in[seqidx].iloc[0, 1:].values)\n",
    "    agent = agent_fn()\n",
    "    done = False\n",
    "    pfan.append([])\n",
    "    pchi.append([])\n",
    "    act.append([])\n",
    "    rewards.append([])\n",
    "    temp.append([])\n",
    "    while not done:\n",
    "        action = agent.predict(state)[0]\n",
    "        state, reward, done, info = esb.step(action)\n",
    "        act[-1].append(action)\n",
    "        # pfan[-1].append(info.get('powfans'))\n",
    "        pchi[-1].append(info.get('powchi'))\n",
    "        rewards[-1].append(reward)\n",
    "        temp[-1].append(info.get('tempcondin'))\n",
    "\n",
    "# get std_dev and mean of metrics\n",
    "# std_pfan = np.std(pfan, axis=0, keepdims=False)\n",
    "std_pchi = np.std(pchi, axis=0, keepdims=False)\n",
    "std_act = np.std(act, axis=0, keepdims=False)\n",
    "std_rewards = np.std(rewards, axis=0, keepdims=False)\n",
    "std_temp = np.std(temp, axis=0, keepdims=False)\n",
    "\n",
    "# pfan = np.mean(pfan, axis=0, keepdims=False)\n",
    "pchi = np.mean(pchi, axis=0, keepdims=False)\n",
    "act = np.mean(act, axis=0, keepdims=False)\n",
    "rewards = np.mean(rewards, axis=0, keepdims=False)\n",
    "temp = np.mean(temp, axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,12))\n",
    "# plt.subplot(4,1,1)\n",
    "# plt.title('Fan Power (Average RL {:.0f}W vs Historical {:.0f}W)'\\\n",
    "#           .format(np.mean(pfan), np.mean(pow_hist_fan)))\n",
    "# plt.plot(pfan, 'b:', label='RL.Fan')\n",
    "# plt.fill_between(np.arange(len(pfan)), pfan+std_pfan, pfan-std_pfan, color='b', alpha=0.3)\n",
    "# plt.plot(pow_hist_fan, 'r:', label='Historical.Fan')\n",
    "# plt.ylim(bottom=0)\n",
    "# plt.legend()\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.title('Chiller Power (Average {:.0f}kW vs Historical {:.0f}kW)'\\\n",
    "          .format(np.mean(pchi), np.mean(pow_hist_chi)))\n",
    "plt.plot(pchi, 'b:', label='Chiller')\n",
    "plt.fill_between(np.arange(len(pchi)), pchi+std_pchi, pchi-std_pchi, color='b', alpha=0.3)\n",
    "plt.plot(pow_hist_chi, 'r:', label='Historical.Chiller')\n",
    "plt.ylim(bottom=0)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.title('Setpoint Control (Average {:.2f} vs Historical {:.2f})'\\\n",
    "          .format(np.mean(act[:, 0]), np.mean(act_hist[:, 0])))\n",
    "plt.plot(ext['TempAmbient'].values, 'g.', label='TempAmbient')\n",
    "plt.plot(ext['TempWetBulb'].values, 'c.', label='TempWetBulb')\n",
    "plt.plot(act[:, 0], 'b:', label='Setpoint')\n",
    "plt.fill_between(np.arange(len(act[:, 0])), act[:, 0]+std_act[:, 0], act[:, 0]-std_act[:, 0], color='b', alpha=0.3)\n",
    "plt.plot(act_hist[:, 0], 'r:', label='Historical.Setpoint')\n",
    "# plt.ylim(top=1.05)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.title('Output Temperature (Average {:.1f}F vs Historical {:.1f}F)'\\\n",
    "          .format(np.mean(temp), np.mean(temp_hist)))\n",
    "plt.plot(temp, 'b:', label='Temp')\n",
    "plt.fill_between(np.arange(len(temp)), temp+std_temp, temp-std_temp, color='b', alpha=0.3)\n",
    "plt.plot(temp_hist, 'r:', label='Historical.Temp')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(dfs_in[seqidx]['TempAmbient'].values, label='Ambient Temp')\n",
    "plt.plot(dfs_in[seqidx]['TempWetBulb'].values, label='WetBulb Temp')\n",
    "plt.legend()\n",
    "plt.ylabel('Temperature /F')\n",
    "plt.title('Environmental Conditions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
